{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import csv\n",
    "import sqlite3\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import chi2, f_classif, SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes = pd.read_csv(\"crash_data_2009.csv\", dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>officer_id</th>\n",
       "      <th>reporting_district</th>\n",
       "      <th>chp_shift</th>\n",
       "      <th>population</th>\n",
       "      <th>county_city_location</th>\n",
       "      <th>county_location</th>\n",
       "      <th>special_condition</th>\n",
       "      <th>beat_type</th>\n",
       "      <th>...</th>\n",
       "      <th>bicyclist_injured_count</th>\n",
       "      <th>motorcyclist_killed_count</th>\n",
       "      <th>motorcyclist_injured_count</th>\n",
       "      <th>primary_ramp</th>\n",
       "      <th>secondary_ramp</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>collision_date</th>\n",
       "      <th>collision_time</th>\n",
       "      <th>process_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3858022</td>\n",
       "      <td>1005</td>\n",
       "      <td>P379</td>\n",
       "      <td>2C</td>\n",
       "      <td>not chp</td>\n",
       "      <td>&gt;250000</td>\n",
       "      <td>1005</td>\n",
       "      <td>fresno</td>\n",
       "      <td>0</td>\n",
       "      <td>not chp</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-02-03</td>\n",
       "      <td>17:11:00</td>\n",
       "      <td>2009-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3899441</td>\n",
       "      <td>9120</td>\n",
       "      <td>17248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2200 thru 0559</td>\n",
       "      <td>2500 to 10000</td>\n",
       "      <td>0801</td>\n",
       "      <td>del norte</td>\n",
       "      <td>0</td>\n",
       "      <td>chp state highway</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-02-28</td>\n",
       "      <td>01:45:00</td>\n",
       "      <td>2009-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3899442</td>\n",
       "      <td>9530</td>\n",
       "      <td>19005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0600 thru 1359</td>\n",
       "      <td>&gt;250000</td>\n",
       "      <td>1942</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>0</td>\n",
       "      <td>chp state highway</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.86465</td>\n",
       "      <td>-118.28533</td>\n",
       "      <td>2009-02-09</td>\n",
       "      <td>10:20:00</td>\n",
       "      <td>2010-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3899445</td>\n",
       "      <td>9530</td>\n",
       "      <td>19284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400 thru 2159</td>\n",
       "      <td>&gt;250000</td>\n",
       "      <td>1942</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>0</td>\n",
       "      <td>chp state highway</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.7912</td>\n",
       "      <td>-118.2823</td>\n",
       "      <td>2009-02-18</td>\n",
       "      <td>15:50:00</td>\n",
       "      <td>2010-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3899446</td>\n",
       "      <td>9530</td>\n",
       "      <td>19289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400 thru 2159</td>\n",
       "      <td>25000 to 50000</td>\n",
       "      <td>1939</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>0</td>\n",
       "      <td>chp state highway</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.8845</td>\n",
       "      <td>-118.3526</td>\n",
       "      <td>2009-02-11</td>\n",
       "      <td>17:35:00</td>\n",
       "      <td>2010-01-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id jurisdiction officer_id reporting_district       chp_shift  \\\n",
       "0  3858022         1005       P379                 2C         not chp   \n",
       "1  3899441         9120      17248                NaN  2200 thru 0559   \n",
       "2  3899442         9530      19005                NaN  0600 thru 1359   \n",
       "3  3899445         9530      19284                NaN  1400 thru 2159   \n",
       "4  3899446         9530      19289                NaN  1400 thru 2159   \n",
       "\n",
       "       population county_city_location county_location special_condition  \\\n",
       "0         >250000                 1005          fresno                 0   \n",
       "1   2500 to 10000                 0801       del norte                 0   \n",
       "2         >250000                 1942     los angeles                 0   \n",
       "3         >250000                 1942     los angeles                 0   \n",
       "4  25000 to 50000                 1939     los angeles                 0   \n",
       "\n",
       "           beat_type  ... bicyclist_injured_count motorcyclist_killed_count  \\\n",
       "0            not chp  ...                       0                         0   \n",
       "1  chp state highway  ...                       0                         0   \n",
       "2  chp state highway  ...                       0                         0   \n",
       "3  chp state highway  ...                       0                         0   \n",
       "4  chp state highway  ...                       0                         0   \n",
       "\n",
       "  motorcyclist_injured_count primary_ramp secondary_ramp  latitude  \\\n",
       "0                          0          NaN            NaN       NaN   \n",
       "1                          0          NaN            NaN       NaN   \n",
       "2                          0          NaN            NaN  33.86465   \n",
       "3                          0          NaN            NaN   33.7912   \n",
       "4                          0          NaN            NaN   33.8845   \n",
       "\n",
       "    longitude collision_date collision_time process_date  \n",
       "0         NaN     2009-02-03       17:11:00   2009-04-27  \n",
       "1         NaN     2009-02-28       01:45:00   2009-11-02  \n",
       "2  -118.28533     2009-02-09       10:20:00   2010-01-14  \n",
       "3   -118.2823     2009-02-18       15:50:00   2010-01-13  \n",
       "4   -118.3526     2009-02-11       17:35:00   2010-01-11  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crashes.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "### drop useless columns\n",
    "\n",
    "### divide features into sparse features and dense features\n",
    "\n",
    "#### sparse feature -> one hot encoder\n",
    "\n",
    "#### dense feature -> Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthCol(df, col):\n",
    "    month = df[col].str.extract(r\"^\\d{4}\\-0(\\d)|^\\d{4}\\-(\\d{2})\", expand=False).values\n",
    "    return pd.Series(month[month == month].astype(int))\n",
    "\n",
    "def hourCol(df, col):\n",
    "    hour = df[col].str.extract(r\"(^[^0]\\d)|^0(\\d)\", expand=False).values\n",
    "    return pd.Series(hour[hour == hour]).astype(int)\n",
    "\n",
    "crashes[\"crash_month\"] = monthCol(crashes, \"collision_date\")\n",
    "crashes[\"crash_hour\"] = hourCol(crashes, \"collision_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 403251 entries, 0 to 403250\n",
      "Data columns (total 77 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   case_id                          403251 non-null  object \n",
      " 1   jurisdiction                     402432 non-null  object \n",
      " 2   officer_id                       401257 non-null  object \n",
      " 3   reporting_district               155928 non-null  object \n",
      " 4   chp_shift                        403251 non-null  object \n",
      " 5   population                       403251 non-null  object \n",
      " 6   county_city_location             403251 non-null  object \n",
      " 7   county_location                  403251 non-null  object \n",
      " 8   special_condition                403251 non-null  object \n",
      " 9   beat_type                        403251 non-null  object \n",
      " 10  chp_beat_type                    403251 non-null  object \n",
      " 11  city_division_lapd               26036 non-null   object \n",
      " 12  chp_beat_class                   403251 non-null  object \n",
      " 13  beat_number                      371279 non-null  object \n",
      " 14  primary_road                     403233 non-null  object \n",
      " 15  secondary_road                   403244 non-null  object \n",
      " 16  distance                         403251 non-null  object \n",
      " 17  direction                        305524 non-null  object \n",
      " 18  intersection                     399261 non-null  object \n",
      " 19  weather_1                        403251 non-null  object \n",
      " 20  weather_2                        11331 non-null   object \n",
      " 21  state_highway_indicator          403202 non-null  object \n",
      " 22  caltrans_county                  148211 non-null  object \n",
      " 23  caltrans_district                148211 non-null  object \n",
      " 24  state_route                      148211 non-null  object \n",
      " 25  route_suffix                     780 non-null     object \n",
      " 26  postmile_prefix                  46913 non-null   object \n",
      " 27  postmile                         148211 non-null  object \n",
      " 28  location_type                    148211 non-null  object \n",
      " 29  ramp_intersection                29534 non-null   object \n",
      " 30  side_of_highway                  148211 non-null  object \n",
      " 31  tow_away                         401372 non-null  object \n",
      " 32  collision_severity               403251 non-null  object \n",
      " 33  killed_victims                   403251 non-null  object \n",
      " 34  injured_victims                  403251 non-null  object \n",
      " 35  party_count                      403251 non-null  object \n",
      " 36  primary_collision_factor         403251 non-null  object \n",
      " 37  pcf_violation_code               2 non-null       object \n",
      " 38  pcf_violation_category           403251 non-null  object \n",
      " 39  pcf_violation                    381078 non-null  object \n",
      " 40  pcf_violation_subsection         147148 non-null  object \n",
      " 41  hit_and_run                      403251 non-null  object \n",
      " 42  type_of_collision                403251 non-null  object \n",
      " 43  motor_vehicle_involved_with      403251 non-null  object \n",
      " 44  pedestrian_action                403251 non-null  object \n",
      " 45  road_surface                     403251 non-null  object \n",
      " 46  road_condition_1                 401399 non-null  object \n",
      " 47  road_condition_2                 995 non-null     object \n",
      " 48  lighting                         403251 non-null  object \n",
      " 49  control_device                   401802 non-null  object \n",
      " 50  chp_road_type                    403251 non-null  object \n",
      " 51  pedestrian_collision             403251 non-null  object \n",
      " 52  bicycle_collision                403251 non-null  object \n",
      " 53  motorcycle_collision             403251 non-null  object \n",
      " 54  truck_collision                  403251 non-null  object \n",
      " 55  not_private_property             403251 non-null  object \n",
      " 56  alcohol_involved                 43628 non-null   object \n",
      " 57  statewide_vehicle_type_at_fault  316074 non-null  object \n",
      " 58  chp_vehicle_type_at_fault        311420 non-null  object \n",
      " 59  severe_injury_count              403251 non-null  object \n",
      " 60  other_visible_injury_count       403251 non-null  object \n",
      " 61  complaint_of_pain_injury_count   403251 non-null  object \n",
      " 62  pedestrian_killed_count          403251 non-null  object \n",
      " 63  pedestrian_injured_count         403251 non-null  object \n",
      " 64  bicyclist_killed_count           403251 non-null  object \n",
      " 65  bicyclist_injured_count          403251 non-null  object \n",
      " 66  motorcyclist_killed_count        403251 non-null  object \n",
      " 67  motorcyclist_injured_count       403251 non-null  object \n",
      " 68  primary_ramp                     12237 non-null   object \n",
      " 69  secondary_ramp                   4673 non-null    object \n",
      " 70  latitude                         116371 non-null  object \n",
      " 71  longitude                        116371 non-null  object \n",
      " 72  collision_date                   403251 non-null  object \n",
      " 73  collision_time                   399956 non-null  object \n",
      " 74  process_date                     403251 non-null  object \n",
      " 75  crash_month                      403251 non-null  int64  \n",
      " 76  crash_hour                       403251 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(75)\n",
      "memory usage: 236.9+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_list = [\"county_location\", \"population\", \"weather_1\", \"road_surface\", \"collision_severity\", \n",
    "              \"lighting\", \"party_count\", \"injured_victims\", \"killed_victims\", \"crash_hour\", \n",
    "              \"crash_month\", \"type_of_collision\", \"hit_and_run\", \"pedestrian_action\", \n",
    "              \"pedestrian_collision\", \"pcf_violation_category\", \"motor_vehicle_involved_with\"]\n",
    "\n",
    "def removeNaN(df, clean_list):\n",
    "    \"\"\"\n",
    "    removes NaN from given features in df\n",
    "    \"\"\"\n",
    "    copy = df.copy()\n",
    "    return copy.dropna(subset=clean_list).reset_index(drop=True)\n",
    "crashes = removeNaN(crashes, clean_list)\n",
    "crashes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\"party_count\", \"injured_victims\", \"killed_victims\", \"crash_hour\", \"crash_month\"]\n",
    "\n",
    "def convertToInt(df, numerical_features):\n",
    "    \"\"\"\n",
    "    converts numerical_features \n",
    "    in df to type int\n",
    "    \"\"\"\n",
    "    copy = df.copy()\n",
    "    for f in numerical_features:\n",
    "        if copy[f].dtype != \"float64\":\n",
    "            copy[f] = crashes[f].astype(int)\n",
    "    return copy\n",
    "crashes = convertToInt(crashes, numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populationConvert(df):\n",
    "    \"\"\"\n",
    "    converts population to state whether\n",
    "    the area of a crash has >100000 population\n",
    "    or <100000 population\n",
    "    \"\"\"\n",
    "    copy = df.copy()\n",
    "    copy[\"population\"] = copy[\"population\"].str.replace(\"unincorporated\", \"1000\")\n",
    "    copy_pop = copy[\"population\"].str.extract(r\"(\\d+)\\s\\w.+|\\>(\\d+)|\\<(\\d+)|[^\\>\\<](\\d+)\", expand=False).values\n",
    "    copy[\"population\"] = pd.Series(copy_pop[copy_pop == copy_pop].astype(int)).apply(lambda num: \">100000\" if num>100000 else \"<100000\")\n",
    "    return copy\n",
    "crashes = populationConvert(crashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features used for classification need to be divided into sparse features and dense features\n",
    "sparse_feature_list = [\"population\", \"weather_1\", \"road_surface\", \"lighting\", \\\n",
    "                       \"crash_hour\", \"crash_month\", 'hit_and_run', 'pedestrian_action', \\\n",
    "                           \"pcf_violation_category\", 'motor_vehicle_involved_with']\n",
    "dense_feature_list = [\"party_count\"]\n",
    "\n",
    "# label to be predicted\n",
    "label_column = 'county_location'\n",
    "\n",
    "# delete columns from drop_list\n",
    "crashes.drop([l for l in crashes.columns if l not in sparse_feature_list + dense_feature_list + [label_column]], axis=1, inplace=True)\n",
    "\n",
    "# preprocess dense feature\n",
    "for feat in dense_feature_list:\n",
    "    scaler = MinMaxScaler()\n",
    "    crashes.loc[:,feat] = scaler.fit_transform(crashes.loc[:, feat].values.reshape(-1, 1))\n",
    "# preprocess label\n",
    "lb = LabelEncoder()\n",
    "crashes.loc[:,label_column] = lb.fit_transform(crashes.loc[:,label_column])\n",
    "# preprocess sparse feature to one hot feature\n",
    "crashes = pd.get_dummies(crashes, columns=sparse_feature_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def myLR(X, Y, val_X, val_Y, max_iter):\n",
    "    lr = LogisticRegression(C=1000, random_state=0, max_iter=max_iter)\n",
    "    lr.fit(X, Y)\n",
    "    return 'lr', accuracy_score(val_Y, lr.predict(val_X))\n",
    "    \n",
    "    \n",
    "    # output = cross_validate(lr, X, Y, cv=10, scoring='accuracy', return_estimator=True)\n",
    "    # metric = output['test_score']\n",
    "    # metric.sort()\n",
    "    # max_acc_estimator = output['estimator'][argmax(output['test_score'])]\n",
    "    # feature_importances = pd.DataFrame(max_acc_estimator.coef_[0],\n",
    "    #                                 index = X.columns,\n",
    "    #                                 columns=['importance']).sort_values('importance', ascending=False)\n",
    "    # return 'lr', metric, feature_importances\n",
    "\n",
    "# SVM with linear regression\n",
    "from sklearn import svm\n",
    "def mySVM(X, Y, val_X, val_Y, max_iter):\n",
    "    svc = svm.SVC(C=1.0, kernel='linear', gamma='auto', max_iter=max_iter)\n",
    "    svc.fit(X, Y)\n",
    "    return 'svm', accuracy_score(val_Y, svc.predict(val_X))\n",
    "    # output = cross_validate(svc, X, Y, cv=10, scoring='accuracy', return_estimator=True)\n",
    "    # metric = output['test_score']\n",
    "    # metric.sort()\n",
    "    # max_acc_estimator = output['estimator'][argmax(output['test_score'])]\n",
    "    # feature_importances = pd.DataFrame(max_acc_estimator.coef_[0],\n",
    "    #                                     index = X.columns,\n",
    "    #                                     columns=['importance']).sort_values('importance', ascending=False)\n",
    "    # return 'svm', metric, feature_importances\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def myRandomForest(X, Y, val_X, val_Y, max_iter):\n",
    "    RF = RandomForestClassifier(n_estimators=30, criterion='gini', random_state=10)\n",
    "    RF.fit(X, Y)\n",
    "    return 'RF', accuracy_score(val_Y, RF.predict(val_X))\n",
    "    \n",
    "    # output = cross_validate(RF, X, Y, cv=10, scoring='accuracy', return_estimator=True)\n",
    "    # metric = output['test_score']\n",
    "    # metric.sort()\n",
    "    # max_acc_estimator = output['estimator'][argmax(output['test_score'])]\n",
    "    # feature_importances = pd.DataFrame(max_acc_estimator.feature_importances_,\n",
    "    #                                     index = X.columns,\n",
    "    #                                     columns=['importance']).sort_values('importance', ascending=False)\n",
    "    # return 'rf', metric, feature_importances\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# NOTE\n",
    "#   Use chi square test to select the features with the\n",
    "#   top K scores (- 1 represents all features), and\n",
    "#   then use these K features for classification\n",
    "def get_k_important_features(k, rawX, rawY):\n",
    "    if k == 'all':\n",
    "        k = len(rawX.columns.values)\n",
    "    model = SelectKBest(chi2, k=k)\n",
    "    X = model.fit_transform(rawX, rawY)\n",
    "    Y = rawY\n",
    "    scores = model.scores_\n",
    "    p_values = model.pvalues_\n",
    "    indices = np.argsort(scores)[::-1]\n",
    "    k_best_features = list(rawX.columns.values[indices[0:k]])\n",
    "    # print(f'k={k} best features are: {str(k_best_features)}')\n",
    "    return k_best_features\n",
    "\n",
    "MAX_ITER = 1000\n",
    "rawX = crashes.drop([label_column], axis=1)\n",
    "rawY = crashes.loc[:, label_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=all best features are: ['population_>100000', 'road_surface_snowy', 'population_<100000', 'weather_1_snowing', 'lighting_dark with no street lights', 'motor_vehicle_involved_with_non-collision', 'motor_vehicle_involved_with_animal', 'motor_vehicle_involved_with_fixed object', 'road_surface_wet', 'lighting_dark with street lights', 'weather_1_cloudy', 'pcf_violation_category_improper turning', 'motor_vehicle_involved_with_other motor vehicle', 'pcf_violation_category_wrong side of road', 'motor_vehicle_involved_with_parked motor vehicle', 'pcf_violation_category_other than driver (or pedestrian)', 'hit_and_run_misdemeanor', 'motor_vehicle_involved_with_pedestrian', 'pcf_violation_category_unsafe lane change', 'pedestrian_action_crossing in intersection crosswalk', 'pcf_violation_category_following too closely', 'weather_1_fog', 'pcf_violation_category_dui', 'hit_and_run_felony', 'pcf_violation_category_unknown', 'pcf_violation_category_speeding', 'pcf_violation_category_automobile right of way', 'weather_1_raining', 'pcf_violation_category_pedestrian right of way', 'motor_vehicle_involved_with_bicycle', 'weather_1_clear', 'pcf_violation_category_other hazardous violation', 'motor_vehicle_involved_with_other object', 'pcf_violation_category_traffic signals and signs', 'road_surface_dry', 'pcf_violation_category_unsafe starting or backing', 'hit_and_run_not hit and run', 'pcf_violation_category_pedestrian violation', 'pedestrian_action_crossing not in crosswalk', 'crash_month_12', 'party_count', 'pcf_violation_category_other improper driving', 'pedestrian_action_in road', 'weather_1_other', 'pcf_violation_category_other equipment', 'lighting_daylight', 'motor_vehicle_involved_with_motor vehicle on other roadway', 'pcf_violation_category_improper passing', 'road_surface_slippery', 'pedestrian_action_not in road', 'crash_month_8', 'crash_month_1', 'crash_month_2', 'motor_vehicle_involved_with_train', 'weather_1_wind', 'pcf_violation_category_hazardous parking', 'pcf_violation_category_brakes', 'crash_month_9', 'crash_month_4', 'pcf_violation_category_impeding traffic', 'crash_month_6', 'crash_month_11', 'crash_month_7', 'pcf_violation_category_lights', 'crash_month_3', 'lighting_dark with street lights not functioning', 'crash_month_5', 'crash_month_10', 'crash_hour_2.0', 'pedestrian_action_crossing non-intersection crosswalk', 'lighting_dusk or dawn', 'crash_hour_18.0', 'pedestrian_action_no pedestrian involved', 'crash_hour_23.0', 'crash_hour_21.0', 'crash_hour_16.0', 'pcf_violation_category_fell asleep', 'crash_hour_0.0', 'crash_hour_4.0', 'crash_hour_12.0', 'crash_hour_17.0', 'crash_hour_6.0', 'crash_hour_3.0', 'crash_hour_5.0', 'crash_hour_7.0', 'crash_hour_11.0', 'crash_hour_10.0', 'crash_hour_14.0', 'crash_hour_8.0', 'crash_hour_1.0', 'crash_hour_15.0', 'crash_hour_22.0', 'crash_hour_9.0', 'crash_hour_20.0', 'crash_hour_19.0', 'crash_hour_13.0', 'pedestrian_action_using school bus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/houpengyu/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/houpengyu/miniforge3/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------K = all best features result------------\n",
      "{'lr': 0.5999057679908744, 'svm': 0.58227297525169866, 'RF': 0.63858056836780242}\n"
     ]
    }
   ],
   "source": [
    "K_list = ['all']\n",
    "classifiers = [myLR, mySVM, myRandomForest]\n",
    "for k in K_list:\n",
    "    k_best_features = get_k_important_features(k, rawX, rawY)\n",
    "    print(f'k={k} best features are: {str(k_best_features)}')\n",
    "    X = rawX[k_best_features]\n",
    "    Y = rawY\n",
    "    X, val_X, Y, val_Y = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "    metric_all = {}\n",
    "    for classifier in classifiers:\n",
    "        ret = classifier(X, Y, val_X, val_Y, MAX_ITER)\n",
    "        feature_importance = None\n",
    "    \n",
    "        if len(ret) == 2:\n",
    "            name, metric = ret\n",
    "        else:\n",
    "            name, metric, feature_importance = ret\n",
    "        if feature_importance is not None:\n",
    "            print(f'K={k} best important features, the feature importance for method {name} is ')\n",
    "            print(feature_importance)\n",
    "        metric_all[name] = metric\n",
    "        print(metric)\n",
    "    print(f'------------------------K = {k} best features result------------')\n",
    "    print(metric_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d867c1f35438287fcc13dc761280ccc18ec8af4832dc195868ce05a278a39cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
